{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- 1. INSTALL ONLY WHAT WE NEED ---\n",
        "!pip install tf-keras keras-cv-attention-models -q\n",
        "\n",
        "# --- 2. THE \"MAGIC\" PATCH (Your Code) ---\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Force Legacy Keras (Keras 2)\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "import tf_keras\n",
        "\n",
        "# Redirect standard Keras calls to tf_keras (The Hot-Swap)\n",
        "sys.modules[\"keras\"] = tf_keras\n",
        "sys.modules[\"tensorflow.keras\"] = tf_keras\n",
        "sys.modules[\"keras.api\"] = tf_keras # Safety measure for newer TF versions\n",
        "sys.modules[\"keras.api._v2\"] = tf_keras # Safety measure\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras_cv_attention_models\n",
        "\n",
        "# Redirect tf.keras explicitly\n",
        "tf.keras = tf_keras\n",
        "\n",
        "print(f\"âœ… TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"âœ… Keras Version: {tf.keras.__version__} (Should be ~2.15 or 2.16)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHDUcFLR6gSy",
        "outputId": "d3a81149-8af7-4ead-f211-59d2e72196bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m802.6/802.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… TensorFlow Version: 2.19.0\n",
            "âœ… Keras Version: 2.19.0 (Should be ~2.15 or 2.16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixmbb57Zk3MU",
        "outputId": "4e2d987a-04c2-4cb9-aebe-1d405d8d9b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”Œ Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "ğŸ“‚ Loading Dataset...\n",
            "ğŸ“Š Preparing 3656 images for MaxViT...\n",
            "ğŸ¤– Loading MaxViT Model...\n",
            "âœ… MaxViT Loaded! Generating predictions...\n",
            "115/115 [==============================] - 605s 5s/step\n",
            "ğŸ‰ PART 1 DONE: Saved to '/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles/maxvit_train_preds.npy'\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# PART 1: MAXVIT GENERATOR (Legacy Keras) -> SAVES TO DRIVE\n",
        "# ==========================================\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. FORCE LEGACY KERAS\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "# 2. INSTALL DEPENDENCIES\n",
        "!pip install tf-keras keras-cv-attention-models -q\n",
        "\n",
        "import tf_keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras_cv_attention_models\n",
        "from google.colab import drive\n",
        "\n",
        "# 3. MOUNT DRIVE\n",
        "print(\"ğŸ”Œ Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 4. PATHS\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "DATA_ROOT = \"/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/maxvit_tiny_skin_model_FINAL_TUNED.keras\"\n",
        "TRAIN_CSV = os.path.join(DATA_ROOT, \"labels.csv\")\n",
        "\n",
        "# *** KEY CHANGE: Save to Drive ***\n",
        "SAVE_PATH = os.path.join(DATA_ROOT, \"maxvit_train_preds.npy\")\n",
        "\n",
        "# 5. CUSTOM OBJECTS\n",
        "def weighted_bce_dummy(y_true, y_pred):\n",
        "    return tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "custom_objects = {\n",
        "    \"weighted_bce\": weighted_bce_dummy,\n",
        "    \"gelu\": tf.nn.gelu,\n",
        "    \"swish\": tf.nn.swish,\n",
        "    \"Functional\": tf_keras.models.Model\n",
        "}\n",
        "\n",
        "# 6. LOAD DATA\n",
        "print(\"ğŸ“‚ Loading Dataset...\")\n",
        "df = pd.read_csv(TRAIN_CSV)\n",
        "df[\"filename\"] = df[\"filename\"].apply(lambda x: os.path.join(DATA_ROOT, x))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "CLASSES = [\"acne\", \"pigmentation\", \"wrinkles\"]\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df[CLASSES])\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42, stratify=train_val_df[CLASSES])\n",
        "\n",
        "def load_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img\n",
        "\n",
        "print(f\"ğŸ“Š Preparing {len(train_df)} images for MaxViT...\")\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(train_df[\"filename\"].values)\n",
        "train_ds = train_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# 7. PREDICT & SAVE\n",
        "if os.path.exists(SAVE_PATH):\n",
        "    print(f\"âš ï¸ File {SAVE_PATH} already exists! Skipping generation.\")\n",
        "else:\n",
        "    print(\"ğŸ¤– Loading MaxViT Model...\")\n",
        "    try:\n",
        "        model = tf_keras.models.load_model(MODEL_PATH, custom_objects=custom_objects, compile=False)\n",
        "        print(\"âœ… MaxViT Loaded! Generating predictions...\")\n",
        "        preds = model.predict(train_ds, verbose=1)\n",
        "        np.save(SAVE_PATH, preds)\n",
        "        print(f\"ğŸ‰ PART 1 DONE: Saved to '{SAVE_PATH}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ MaxViT Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 2: EFFICIENTNET GENERATOR (Modern Keras) -> SAVES TO DRIVE\n",
        "# ==========================================\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. FORCE UNSET LEGACY MODE\n",
        "if \"TF_USE_LEGACY_KERAS\" in os.environ:\n",
        "    del os.environ[\"TF_USE_LEGACY_KERAS\"]\n",
        "\n",
        "# 2. UPDATE KERAS\n",
        "!pip install keras --upgrade -q\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# 3. MOUNT DRIVE\n",
        "print(\"ğŸ”Œ Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 4. PATHS\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "DATA_ROOT = \"/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/efficientnetv2s_se_best.keras\"\n",
        "TRAIN_CSV = os.path.join(DATA_ROOT, \"labels.csv\")\n",
        "\n",
        "# *** KEY CHANGE: Save to Drive ***\n",
        "SAVE_PATH = os.path.join(DATA_ROOT, \"effnet_train_preds.npy\")\n",
        "\n",
        "# 5. CUSTOM OBJECTS\n",
        "@keras.saving.register_keras_serializable()\n",
        "def weighted_bce(y_true, y_pred):\n",
        "    return keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "# 6. LOAD DATA\n",
        "print(\"ğŸ“‚ Loading Dataset...\")\n",
        "df = pd.read_csv(TRAIN_CSV)\n",
        "df[\"filename\"] = df[\"filename\"].apply(lambda x: os.path.join(DATA_ROOT, x))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "CLASSES = [\"acne\", \"pigmentation\", \"wrinkles\"]\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df[CLASSES])\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42, stratify=train_val_df[CLASSES])\n",
        "\n",
        "def load_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img\n",
        "\n",
        "print(f\"ğŸ“Š Preparing {len(train_df)} images for EfficientNet...\")\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(train_df[\"filename\"].values)\n",
        "train_ds = train_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# 7. PREDICT & SAVE\n",
        "if os.path.exists(SAVE_PATH):\n",
        "    print(f\"âš ï¸ File {SAVE_PATH} already exists! Skipping generation.\")\n",
        "else:\n",
        "    print(\"ğŸ¤– Loading EfficientNet Model...\")\n",
        "    try:\n",
        "        model = keras.saving.load_model(MODEL_PATH, compile=False)\n",
        "        print(\"âœ… EfficientNet Loaded! Generating predictions...\")\n",
        "        preds = model.predict(train_ds, verbose=1)\n",
        "        np.save(SAVE_PATH, preds)\n",
        "        print(f\"ğŸ‰ PART 2 DONE: Saved to '{SAVE_PATH}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ EfficientNet Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_2BTxx9G70b",
        "outputId": "1df397fd-db01-46ea-f75f-036f94356f51"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.7/1.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hğŸ”Œ Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "ğŸ“‚ Loading Dataset...\n",
            "ğŸ“Š Preparing 3656 images for EfficientNet...\n",
            "ğŸ¤– Loading EfficientNet Model...\n",
            "âœ… EfficientNet Loaded! Generating predictions...\n",
            "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 6s/step\n",
            "ğŸ‰ PART 2 DONE: Saved to '/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles/effnet_train_preds.npy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Ensure Drive is accessible\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "DATA_ROOT = \"/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles\"\n",
        "\n",
        "# 1. PATHS TO LOAD FROM DRIVE\n",
        "maxvit_path = os.path.join(DATA_ROOT, \"maxvit_train_preds.npy\")\n",
        "effnet_path = os.path.join(DATA_ROOT, \"effnet_train_preds.npy\")\n",
        "save_path = \"teacher_train_probs.npy\" # Save locally for training (or change to DATA_ROOT to save to drive)\n",
        "\n",
        "# 2. CHECK & MERGE\n",
        "if os.path.exists(maxvit_path) and os.path.exists(effnet_path):\n",
        "    print(\"ğŸ”„ Found both files on Drive. Merging...\")\n",
        "\n",
        "    maxvit_preds = np.load(maxvit_path)\n",
        "    effnet_preds = np.load(effnet_path)\n",
        "\n",
        "    # Ensemble Logic\n",
        "    teacher_train_probs = (0.7 * maxvit_preds) + (0.3 * effnet_preds)\n",
        "\n",
        "    np.save(save_path, teacher_train_probs)\n",
        "    print(f\"ğŸ† SUCCESS! Final soft labels saved as '{save_path}'\")\n",
        "    print(f\"Shape: {teacher_train_probs.shape}\")\n",
        "    print(\"You can now proceed to train your MobileViT student!\")\n",
        "else:\n",
        "    print(\"âŒ One or both prediction files are missing from Google Drive.\")\n",
        "    print(f\"Checking MaxViT: {maxvit_path} -> {os.path.exists(maxvit_path)}\")\n",
        "    print(f\"Checking EffNet: {effnet_path} -> {os.path.exists(effnet_path)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3tpXE0dG_NZ",
        "outputId": "e6c1c1a1-3d61-4c83-adaa-96a70873d903"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ğŸ”„ Found both files on Drive. Merging...\n",
            "ğŸ† SUCCESS! Final soft labels saved as 'teacher_train_probs.npy'\n",
            "Shape: (3656, 3)\n",
            "You can now proceed to train your MobileViT student!\n"
          ]
        }
      ]
    }
  ]
}