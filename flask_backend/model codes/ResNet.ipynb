{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ2CAWALWd8o",
        "outputId": "e2c874ac-11d9-4013-e291-dc8c6facad04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "TensorFlow Version: 2.19.0\n",
            "KerasTuner Version: 1.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import keras_tuner\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"KerasTuner Version:\", keras_tuner.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "CLASSES = [\"acne\", \"pigmentation\", \"wrinkles\"]\n",
        "DATA_ROOT = \"/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles/\"\n",
        "\n",
        "df = pd.read_csv(os.path.join(DATA_ROOT, \"labels.csv\"))\n",
        "df[\"filename\"] = df[\"filename\"].apply(lambda x: os.path.join(DATA_ROOT, x))"
      ],
      "metadata": {
        "id": "gYrQrc3EWpgm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df[CLASSES])\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42, stratify=train_val_df[CLASSES])\n",
        "\n",
        "pos_counts = train_df[CLASSES].sum().values\n",
        "total_train_samples = len(train_df)"
      ],
      "metadata": {
        "id": "SAuDs9PEGxDW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "#Create tf.data Pipelines\n",
        "def parse_function(filename, labels):\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image_decoded = tf.io.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
        "    image_resized = tf.image.resize(image, IMG_SIZE)\n",
        "    return image_resized, labels\n",
        "\n",
        "def create_dataset(df, batch_size, augment=False, cache_file=None):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (df[\"filename\"].values, df[CLASSES].values.astype(np.float32))\n",
        "    )\n",
        "    dataset = dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if augment:\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                              num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if cache_file:\n",
        "        dataset = dataset.cache(cache_file)\n",
        "    else:\n",
        "        dataset = dataset.cache()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "train_cache_file = os.path.join(DATA_ROOT, 'resnet_train_cache')\n",
        "val_cache_file = os.path.join(DATA_ROOT, 'resnet_val_cache')\n",
        "\n",
        "#Create the datasets\n",
        "train_ds = create_dataset(train_df, BATCH_SIZE, augment=True, cache_file=train_cache_file)\n",
        "val_ds = create_dataset(val_df, BATCH_SIZE, augment=False, cache_file=val_cache_file)\n",
        "test_ds = create_dataset(test_df, BATCH_SIZE, augment=False)\n",
        "\n",
        "print(\"tf.data pipelines created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkQzbcqEG2b6",
        "outputId": "957ea9e2-7c23-4eb8-b83a-5a74ac184d6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.data pipelines created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hyper_model(hp):\n",
        "    #Defining Hyperparameter for Dropout\n",
        "    hp_dropout = hp.Float('dropout', 0.2, 0.5, step=0.1)\n",
        "\n",
        "    #Load the ResNet50V2 base model\n",
        "    base_model = ResNet50V2(\n",
        "        include_top=False,\n",
        "        input_shape=IMG_SIZE + (3,),\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
        "    x = tf.keras.applications.resnet_v2.preprocess_input(inputs)\n",
        "    x = base_model(x, training=base_model.trainable) #training=False in stage 1\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(hp_dropout)(x) #Using tunable dropout\n",
        "    outputs = layers.Dense(len(CLASSES), activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs, outputs, name=\"resnet50v2_hyper_model\")\n",
        "    return model\n",
        "\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "c3mM-DZQG8HH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Serializable Weighted BCE Loss\n",
        "def create_weighted_bce_loss(pos_counts, total_samples, smooth=0.05):\n",
        "\n",
        "    #A factory function that creates a weighted BCE loss function.\n",
        "    pos = tf.constant(pos_counts, dtype=tf.float32)\n",
        "    neg = total_samples - pos\n",
        "    w_pos = neg / tf.maximum(pos, 1.0)\n",
        "    w_neg = tf.ones_like(pos)\n",
        "\n",
        "    def weighted_bce(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "        y_true = y_true * (1.0 - smooth) + 0.5 * smooth\n",
        "        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
        "        weights = y_true * w_pos + (1.0 - y_true) * w_neg\n",
        "        return tf.reduce_mean(bce * weights)\n",
        "\n",
        "    return weighted_bce\n",
        "\n",
        "#Creating the loss function instance and custom_objects dict\n",
        "loss_fn = create_weighted_bce_loss(pos_counts, total_train_samples)\n",
        "\n",
        "#Custom Objects needed for loading/saving\n",
        "custom_objects = {\n",
        "    \"weighted_bce\": loss_fn\n",
        "}"
      ],
      "metadata": {
        "id": "SzeVkShUHCoR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTuner(keras_tuner.RandomSearch):\n",
        "\n",
        "    #Custom Tuner for two-stage training.\n",
        "    def __init__(self, loss_function, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_function = loss_function\n",
        "\n",
        "    def run_trial(self, trial, train_ds, val_ds, **kwargs):\n",
        "        hp = trial.hyperparameters\n",
        "        model = self.hypermodel.build(hp)\n",
        "\n",
        "        all_metrics = [\n",
        "            tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5),\n",
        "            tf.keras.metrics.AUC(name=\"auc\", multi_label=True),\n",
        "            tf.keras.metrics.Precision(name=\"precision\", thresholds=0.5),\n",
        "            tf.keras.metrics.Recall(name=\"recall\", thresholds=0.5),\n",
        "        ]\n",
        "\n",
        "        #STAGE 1: Train the Head\n",
        "        print(f\"\\n[Trial {trial.trial_id}] Stage 1: Training head...\")\n",
        "        head_lr = hp.Float('head_lr', 1e-4, 1e-3, sampling='log')\n",
        "\n",
        "        #Layer name must match your model\n",
        "        model.get_layer(\"resnet50v2\").trainable = False\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=AdamW(learning_rate=head_lr, weight_decay=1e-4),\n",
        "            loss=self.loss_function,\n",
        "            metrics=all_metrics\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=10,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        #STAGE 2: Fine-Tuning\n",
        "        print(f\"\\n[Trial {trial.trial_id}] Stage 2: Fine-tuning...\")\n",
        "        finetune_lr = hp.Float('finetune_lr', 1e-6, 5e-5, sampling='log')\n",
        "\n",
        "        #Layer name must match your model\n",
        "        model.get_layer(\"resnet50v2\").trainable = True\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=AdamW(learning_rate=finetune_lr, weight_decay=1e-4),\n",
        "            loss=self.loss_function,\n",
        "            metrics=all_metrics\n",
        "        )\n",
        "\n",
        "        callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor=\"val_auc\",\n",
        "                mode=\"max\",\n",
        "                patience=5,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor=\"val_auc\",\n",
        "                mode=\"max\",\n",
        "                factor=0.2,\n",
        "                patience=5\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=40,\n",
        "            callbacks=callbacks,\n",
        "            initial_epoch=10,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(f\"[Trial {trial.trial_id}] Evaluating best weights on val_ds...\")\n",
        "        eval_results = model.evaluate(val_ds, return_dict=True, verbose=0)\n",
        "\n",
        "        val_results_with_prefix = {f\"val_{k}\": v for k, v in eval_results.items()}\n",
        "        return val_results_with_prefix"
      ],
      "metadata": {
        "id": "LRHL2S2uHNwZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the tuner\n",
        "tuner = CustomTuner(\n",
        "    loss_function=loss_fn,\n",
        "    hypermodel=build_hyper_model,\n",
        "    objective=keras_tuner.Objective(\"val_auc\", direction=\"max\"),\n",
        "\n",
        "    max_trials=5,\n",
        "\n",
        "    executions_per_trial=1,\n",
        "    directory=os.path.join(DATA_ROOT, 'keras_tuner'),\n",
        "    project_name='resnet_skin_tuning',\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "#Printing a summary of the search space\n",
        "tuner.search_space_summary()\n",
        "\n",
        "#Starting the search\n",
        "print(\"\\nStarting hyperparameter search...\")\n",
        "start_time = time.time()\n",
        "\n",
        "tuner.search(\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTotal search time: {(end_time - start_time) / 60:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1Bq4tSkyvM8",
        "outputId": "0d8de16e-b5f8-4e96-f1c6-6275a406b37b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 12m 04s]\n",
            "val_auc: 0.9870684742927551\n",
            "\n",
            "Best val_auc So Far: 0.9870684742927551\n",
            "Total elapsed time: 00h 59m 56s\n",
            "\n",
            "Total search time: 59.93 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the Best Hyperparameters\n",
        "print(\"\\nTop Trials\")\n",
        "tuner.results_summary(num_trials=5)\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"\\nBest Hyperparameters Found\")\n",
        "print(f\"Dropout: {best_hps.get('dropout'):.3f}\")\n",
        "print(f\"Head LR: {best_hps.get('head_lr'):.1e}\")\n",
        "print(f\"Finetune LR: {best_hps.get('finetune_lr'):.1e}\")\n",
        "\n",
        "#Building the FINAL Best Model\n",
        "print(\"\\nBuilding the best model for final training...\")\n",
        "final_model = build_hyper_model(best_hps)\n",
        "final_model.summary()\n",
        "\n",
        "#Defining Callbacks for FINAL Training\n",
        "FINAL_MODEL_PATH = os.path.join(DATA_ROOT, \"resnet_skin_model_FINAL_TUNED.keras\")\n",
        "final_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=7, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\", factor=0.2, patience=3, min_lr=1e-6),\n",
        "    tf.keras.callbacks.ModelCheckpoint(FINAL_MODEL_PATH, monitor=\"val_auc\", mode=\"max\", save_best_only=True)\n",
        "]\n",
        "\n",
        "#STAGE 1: Train the Head (Full Epochs)\n",
        "print(\"\\nFinal Training: STAGE 1 (Head)\")\n",
        "final_head_lr = best_hps.get('head_lr')\n",
        "\n",
        "final_model.get_layer(\"resnet50v2\").trainable = False\n",
        "final_model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=final_head_lr, weight_decay=1e-4),\n",
        "    loss=loss_fn,\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5),\n",
        "        tf.keras.metrics.AUC(name=\"auc\", multi_label=True),\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\")\n",
        "    ]\n",
        ")\n",
        "start_time_stage1 = time.time()\n",
        "history_head = final_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")\n",
        "end_time_stage1 = time.time()\n",
        "\n",
        "#STAGE 2: Fine-Tuning (Full Epochs)\n",
        "print(\"\\nFinal Training: STAGE 2 (Fine-Tune)\")\n",
        "final_finetune_lr = best_hps.get('finetune_lr')\n",
        "\n",
        "final_model.get_layer(\"resnet50v2\").trainable = True\n",
        "final_model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=final_finetune_lr, weight_decay=1e-4),\n",
        "    loss=loss_fn,\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5),\n",
        "        tf.keras.metrics.AUC(name=\"auc\", multi_label=True),\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\")\n",
        "    ]\n",
        ")\n",
        "start_time_stage2 = time.time()\n",
        "history_fine_tune = final_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=70,\n",
        "    callbacks=final_callbacks,\n",
        "    initial_epoch=len(history_head.history['loss']),\n",
        "    verbose=1\n",
        ")\n",
        "end_time_stage2 = time.time()"
      ],
      "metadata": {
        "id": "W4MHO3shy7Zz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "375b7311-6fcd-4244-bf8b-0ce51a4c744d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top Trials\n",
            "Results summary\n",
            "Results in /content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles/keras_tuner/resnet_skin_tuning\n",
            "Showing 5 best trials\n",
            "Objective(name=\"val_auc\", direction=\"max\")\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "dropout: 0.2\n",
            "head_lr: 0.0002667602575502906\n",
            "finetune_lr: 2.4331543558259883e-05\n",
            "Score: 0.9870684742927551\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "dropout: 0.2\n",
            "head_lr: 0.00026479831891630407\n",
            "finetune_lr: 7.699317528409584e-06\n",
            "Score: 0.9864333271980286\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "dropout: 0.2\n",
            "head_lr: 0.0007959937530049706\n",
            "finetune_lr: 2.3715642364138958e-05\n",
            "Score: 0.9831721186637878\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "dropout: 0.4\n",
            "head_lr: 0.0007151963634216637\n",
            "finetune_lr: 1e-06\n",
            "Score: 0.9620389938354492\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "dropout: 0.30000000000000004\n",
            "head_lr: 0.0001\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
            "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3718811298.py\", line 32, in run_trial\n",
            "    model.fit(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
            "    except TypeError as e:\n",
            "tensorflow.python.framework.errors_impl.AlreadyExistsError: Graph execution error:\n",
            "\n",
            "Detected at node IteratorGetNext defined at (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "\n",
            "  File \"/tmp/ipython-input-3802141758.py\", line 22, in <cell line: 0>\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
            "\n",
            "  File \"/tmp/ipython-input-3718811298.py\", line 32, in run_trial\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n",
            "\n",
            "Detected at node IteratorGetNext defined at (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "\n",
            "  File \"/tmp/ipython-input-3802141758.py\", line 22, in <cell line: 0>\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
            "\n",
            "  File \"/tmp/ipython-input-3718811298.py\", line 32, in run_trial\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n",
            "\n",
            "2 root error(s) found.\n",
            "  (0) ALREADY_EXISTS:  There appears to be a concurrent caching iterator running - cache lockfile already exists ('/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles/resnet_train_cache_0.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1762256298\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "\t [[IteratorGetNext/_2]]\n",
            "  (1) ALREADY_EXISTS:  There appears to be a concurrent caching iterator running - cache lockfile already exists ('/content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles/resnet_train_cache_0.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1762256298\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored. [Op:__inference_multi_step_on_iterator_15878]\n",
            "\n",
            "\n",
            "Best Hyperparameters Found\n",
            "Dropout: 0.200\n",
            "Head LR: 2.7e-04\n",
            "Finetune LR: 2.4e-05\n",
            "\n",
            "Building the best model for final training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"resnet50v2_hyper_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"resnet50v2_hyper_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ true_divide_6 (\u001b[38;5;33mTrueDivide\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ subtract_6 (\u001b[38;5;33mSubtract\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m6,147\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ true_divide_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ subtract_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,147</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,570,947\u001b[0m (89.92 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,570,947</span> (89.92 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,525,507\u001b[0m (89.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,525,507</span> (89.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Training: STAGE 1 (Head)\n",
            "Epoch 1/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 218ms/step - acc: 0.6886 - auc: 0.5917 - loss: 1.1525 - precision: 0.2402 - recall: 0.2826 - val_acc: 0.8318 - val_auc: 0.8562 - val_loss: 1.0730 - val_precision: 0.5640 - val_recall: 0.6058\n",
            "Epoch 2/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - acc: 0.7658 - auc: 0.7723 - loss: 1.0591 - precision: 0.4287 - recall: 0.6272 - val_acc: 0.8313 - val_auc: 0.8730 - val_loss: 1.0191 - val_precision: 0.5495 - val_recall: 0.7487\n",
            "Epoch 3/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - acc: 0.7818 - auc: 0.8243 - loss: 1.0038 - precision: 0.4606 - recall: 0.7373 - val_acc: 0.8308 - val_auc: 0.8785 - val_loss: 0.9789 - val_precision: 0.5470 - val_recall: 0.7698\n",
            "Epoch 4/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - acc: 0.7918 - auc: 0.8480 - loss: 0.9631 - precision: 0.4770 - recall: 0.7760 - val_acc: 0.8323 - val_auc: 0.8820 - val_loss: 0.9482 - val_precision: 0.5477 - val_recall: 0.8042\n",
            "Epoch 5/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - acc: 0.7993 - auc: 0.8604 - loss: 0.9290 - precision: 0.4889 - recall: 0.8003 - val_acc: 0.8292 - val_auc: 0.8845 - val_loss: 0.9231 - val_precision: 0.5414 - val_recall: 0.8122\n",
            "Epoch 6/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - acc: 0.7979 - auc: 0.8656 - loss: 0.9067 - precision: 0.4868 - recall: 0.8048 - val_acc: 0.8302 - val_auc: 0.8864 - val_loss: 0.9030 - val_precision: 0.5429 - val_recall: 0.8201\n",
            "Epoch 7/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - acc: 0.7981 - auc: 0.8716 - loss: 0.8821 - precision: 0.4874 - recall: 0.8217 - val_acc: 0.8390 - val_auc: 0.8888 - val_loss: 0.8854 - val_precision: 0.5589 - val_recall: 0.8280\n",
            "Epoch 8/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - acc: 0.8078 - auc: 0.8775 - loss: 0.8623 - precision: 0.5024 - recall: 0.8253 - val_acc: 0.8344 - val_auc: 0.8908 - val_loss: 0.8705 - val_precision: 0.5496 - val_recall: 0.8360\n",
            "Epoch 9/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - acc: 0.8030 - auc: 0.8774 - loss: 0.8513 - precision: 0.4949 - recall: 0.8308 - val_acc: 0.8416 - val_auc: 0.8924 - val_loss: 0.8576 - val_precision: 0.5637 - val_recall: 0.8307\n",
            "Epoch 10/10\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - acc: 0.8099 - auc: 0.8832 - loss: 0.8344 - precision: 0.5056 - recall: 0.8308 - val_acc: 0.8437 - val_auc: 0.8939 - val_loss: 0.8460 - val_precision: 0.5676 - val_recall: 0.8333\n",
            "\n",
            "Final Training: STAGE 2 (Fine-Tune)\n",
            "Epoch 11/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 604ms/step - acc: 0.7489 - auc: 0.7655 - loss: 2.7373 - precision: 0.3925 - recall: 0.5366 - val_acc: 0.4107 - val_auc: 0.6165 - val_loss: 1.7232 - val_precision: 0.1968 - val_recall: 0.6561 - learning_rate: 2.4332e-05\n",
            "Epoch 12/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 296ms/step - acc: 0.9390 - auc: 0.9857 - loss: 0.4198 - precision: 0.7912 - recall: 0.9342 - val_acc: 0.5490 - val_auc: 0.6407 - val_loss: 1.7634 - val_precision: 0.1427 - val_recall: 0.2619 - learning_rate: 2.4332e-05\n",
            "Epoch 13/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 382ms/step - acc: 0.9809 - auc: 0.9981 - loss: 0.2888 - precision: 0.9232 - recall: 0.9836 - val_acc: 0.5573 - val_auc: 0.7426 - val_loss: 1.5093 - val_precision: 0.1364 - val_recall: 0.2381 - learning_rate: 2.4332e-05\n",
            "Epoch 14/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 360ms/step - acc: 0.9949 - auc: 0.9998 - loss: 0.2429 - precision: 0.9759 - recall: 0.9986 - val_acc: 0.5913 - val_auc: 0.8000 - val_loss: 1.6274 - val_precision: 0.1725 - val_recall: 0.2884 - learning_rate: 2.4332e-05\n",
            "Epoch 15/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 346ms/step - acc: 0.9987 - auc: 1.0000 - loss: 0.2248 - precision: 0.9935 - recall: 1.0000 - val_acc: 0.6842 - val_auc: 0.8794 - val_loss: 1.1280 - val_precision: 0.2983 - val_recall: 0.4577 - learning_rate: 2.4332e-05\n",
            "Epoch 16/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 349ms/step - acc: 0.9997 - auc: 1.0000 - loss: 0.2168 - precision: 0.9987 - recall: 1.0000 - val_acc: 0.7379 - val_auc: 0.9313 - val_loss: 0.9291 - val_precision: 0.3801 - val_recall: 0.5450 - learning_rate: 2.4332e-05\n",
            "Epoch 17/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 351ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2137 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.8695 - val_auc: 0.9551 - val_loss: 0.6753 - val_precision: 0.6478 - val_recall: 0.7249 - learning_rate: 2.4332e-05\n",
            "Epoch 18/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 382ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2110 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9407 - val_auc: 0.9729 - val_loss: 0.4872 - val_precision: 0.8200 - val_recall: 0.8915 - learning_rate: 2.4332e-05\n",
            "Epoch 19/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 332ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2091 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.8075 - val_auc: 0.8461 - val_loss: 1.0937 - val_precision: 0.5072 - val_recall: 0.4656 - learning_rate: 2.4332e-05\n",
            "Epoch 20/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 273ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2077 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9025 - val_auc: 0.9567 - val_loss: 0.6209 - val_precision: 0.7534 - val_recall: 0.7434 - learning_rate: 2.4332e-05\n",
            "Epoch 21/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2067 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9474 - val_auc: 0.9712 - val_loss: 0.4847 - val_precision: 0.8575 - val_recall: 0.8757 - learning_rate: 2.4332e-05\n",
            "Epoch 22/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 299ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2067 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9752 - val_auc: 0.9885 - val_loss: 0.3738 - val_precision: 0.9275 - val_recall: 0.9471 - learning_rate: 4.8663e-06\n",
            "Epoch 23/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 352ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2054 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9768 - val_auc: 0.9886 - val_loss: 0.3818 - val_precision: 0.9325 - val_recall: 0.9497 - learning_rate: 4.8663e-06\n",
            "Epoch 24/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 330ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2045 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9675 - val_auc: 0.9839 - val_loss: 0.4179 - val_precision: 0.9112 - val_recall: 0.9233 - learning_rate: 4.8663e-06\n",
            "Epoch 25/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 276ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2039 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9742 - val_auc: 0.9883 - val_loss: 0.3699 - val_precision: 0.9227 - val_recall: 0.9471 - learning_rate: 4.8663e-06\n",
            "Epoch 26/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 325ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2036 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9768 - val_auc: 0.9902 - val_loss: 0.3635 - val_precision: 0.9347 - val_recall: 0.9471 - learning_rate: 4.8663e-06\n",
            "Epoch 27/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 341ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2036 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9768 - val_auc: 0.9899 - val_loss: 0.3696 - val_precision: 0.9280 - val_recall: 0.9550 - learning_rate: 4.8663e-06\n",
            "Epoch 28/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2034 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9757 - val_auc: 0.9886 - val_loss: 0.3668 - val_precision: 0.9276 - val_recall: 0.9497 - learning_rate: 4.8663e-06\n",
            "Epoch 29/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 276ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2032 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9768 - val_auc: 0.9896 - val_loss: 0.3608 - val_precision: 0.9302 - val_recall: 0.9524 - learning_rate: 4.8663e-06\n",
            "Epoch 30/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 277ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2030 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9778 - val_auc: 0.9896 - val_loss: 0.3645 - val_precision: 0.9373 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 31/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 282ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2030 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9773 - val_auc: 0.9899 - val_loss: 0.3650 - val_precision: 0.9349 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 32/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 317ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2029 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9778 - val_auc: 0.9904 - val_loss: 0.3633 - val_precision: 0.9373 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 33/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 358ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2024 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9773 - val_auc: 0.9905 - val_loss: 0.3628 - val_precision: 0.9326 - val_recall: 0.9524 - learning_rate: 1.0000e-06\n",
            "Epoch 34/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 342ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2025 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9788 - val_auc: 0.9898 - val_loss: 0.3635 - val_precision: 0.9423 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 35/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 277ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2025 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9768 - val_auc: 0.9903 - val_loss: 0.3610 - val_precision: 0.9347 - val_recall: 0.9471 - learning_rate: 1.0000e-06\n",
            "Epoch 36/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 316ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2024 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9778 - val_auc: 0.9909 - val_loss: 0.3584 - val_precision: 0.9351 - val_recall: 0.9524 - learning_rate: 1.0000e-06\n",
            "Epoch 37/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 346ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2023 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9773 - val_auc: 0.9897 - val_loss: 0.3649 - val_precision: 0.9349 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 38/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 276ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2024 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9763 - val_auc: 0.9894 - val_loss: 0.3694 - val_precision: 0.9301 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 39/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 276ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2023 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9763 - val_auc: 0.9900 - val_loss: 0.3647 - val_precision: 0.9323 - val_recall: 0.9471 - learning_rate: 1.0000e-06\n",
            "Epoch 40/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 304ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2021 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9773 - val_auc: 0.9910 - val_loss: 0.3575 - val_precision: 0.9326 - val_recall: 0.9524 - learning_rate: 1.0000e-06\n",
            "Epoch 41/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 333ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2021 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9768 - val_auc: 0.9908 - val_loss: 0.3653 - val_precision: 0.9347 - val_recall: 0.9471 - learning_rate: 1.0000e-06\n",
            "Epoch 42/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 277ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2019 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9778 - val_auc: 0.9894 - val_loss: 0.3646 - val_precision: 0.9373 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 43/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2020 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9788 - val_auc: 0.9893 - val_loss: 0.3637 - val_precision: 0.9377 - val_recall: 0.9550 - learning_rate: 1.0000e-06\n",
            "Epoch 44/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 278ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2021 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9763 - val_auc: 0.9908 - val_loss: 0.3623 - val_precision: 0.9323 - val_recall: 0.9471 - learning_rate: 1.0000e-06\n",
            "Epoch 45/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2018 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9778 - val_auc: 0.9906 - val_loss: 0.3645 - val_precision: 0.9373 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 46/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 283ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2020 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9773 - val_auc: 0.9894 - val_loss: 0.3679 - val_precision: 0.9326 - val_recall: 0.9524 - learning_rate: 1.0000e-06\n",
            "Epoch 47/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 300ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2018 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9778 - val_auc: 0.9913 - val_loss: 0.3617 - val_precision: 0.9396 - val_recall: 0.9471 - learning_rate: 1.0000e-06\n",
            "Epoch 48/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 337ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2018 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9763 - val_auc: 0.9903 - val_loss: 0.3683 - val_precision: 0.9346 - val_recall: 0.9444 - learning_rate: 1.0000e-06\n",
            "Epoch 49/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 283ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2016 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9768 - val_auc: 0.9906 - val_loss: 0.3687 - val_precision: 0.9370 - val_recall: 0.9444 - learning_rate: 1.0000e-06\n",
            "Epoch 50/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 278ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2018 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9773 - val_auc: 0.9881 - val_loss: 0.3671 - val_precision: 0.9349 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 51/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2017 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9757 - val_auc: 0.9874 - val_loss: 0.3771 - val_precision: 0.9233 - val_recall: 0.9550 - learning_rate: 1.0000e-06\n",
            "Epoch 52/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2013 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9752 - val_auc: 0.9886 - val_loss: 0.3763 - val_precision: 0.9253 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 53/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2015 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9788 - val_auc: 0.9905 - val_loss: 0.3590 - val_precision: 0.9423 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n",
            "Epoch 54/70\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 284ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2014 - precision: 1.0000 - recall: 1.0000 - val_acc: 0.9778 - val_auc: 0.9898 - val_loss: 0.3661 - val_precision: 0.9373 - val_recall: 0.9497 - learning_rate: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Evaluation on Test Set\n",
        "print(f\"\\nLoading best saved final model from: {FINAL_MODEL_PATH}\")\n",
        "loaded_best_model = tf.keras.models.load_model(\n",
        "    FINAL_MODEL_PATH,\n",
        "    custom_objects=custom_objects\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating the final tuned ResNet model on the test set...\")\n",
        "test_results = loaded_best_model.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "print(\"\\nFinal ResNet Test Set Evaluation Results\")\n",
        "precision = 0.0\n",
        "recall = 0.0\n",
        "for metric, value in test_results.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "    if metric == \"precision\":\n",
        "        precision = value\n",
        "    if metric == \"recall\":\n",
        "        recall = value\n",
        "\n",
        "if precision + recall > 0:\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(f\"f1_score (calculated): {f1_score:.4f}\")\n",
        "else:\n",
        "    print(\"f1_score (calculated): 0.0\")\n",
        "\n",
        "#Print Stats\n",
        "print(\"\\nFinal Model Stats\")\n",
        "if os.path.exists(FINAL_MODEL_PATH):\n",
        "    file_size_mb = os.path.getsize(FINAL_MODEL_PATH) / (1024 * 1024)\n",
        "    print(f\"Model Size on Disk: {file_size_mb:.2f} MB\")\n",
        "\n",
        "total_time_sec = (end_time_stage1 - start_time_stage1) + (end_time_stage2 - start_time_stage2)\n",
        "total_epochs_ran = len(history_head.history['loss']) + len(history_fine_tune.history['loss'])\n",
        "avg_time_per_epoch_sec = total_time_sec / total_epochs_ran\n",
        "print(f\"Total Training Time: {total_time_sec / 60:.2f} minutes\")\n",
        "print(f\"Total Epochs Trained: {total_epochs_ran}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq2GRAwPy3S3",
        "outputId": "af429ddd-3d1c-4078-e749-152d25bac6f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading best saved final model from: /content/drive/MyDrive/skincareapp/acne clean pigmentation wrinkles/resnet_skin_model_FINAL_TUNED.keras\n",
            "\n",
            "Evaluating the final tuned ResNet model on the test set...\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 453ms/step - acc: 0.9778 - auc: 0.9940 - loss: 0.3217 - precision: 0.9416 - recall: 0.9406\n",
            "\n",
            "Final ResNet Test Set Evaluation Results\n",
            "acc: 0.9768\n",
            "auc: 0.9925\n",
            "loss: 0.3556\n",
            "precision: 0.9395\n",
            "recall: 0.9416\n",
            "f1_score (calculated): 0.9405\n",
            "\n",
            "Final Model Stats\n",
            "Model Size on Disk: 270.18 MB\n",
            "Total Training Time: 29.85 minutes\n",
            "Total Epochs Trained: 54\n"
          ]
        }
      ]
    }
  ]
}